# Colab Notebooks

- [2.3. Byte-Pair Encoding](https://github.com/aburkov/theLMbook/blob/main/byte_pair_encoding.ipynb)
- [2.5. Count-Based Language Model](https://github.com/aburkov/theLMbook/blob/main/count_language_model.ipynb)
- [3.6. Training an RNN Language Model](https://github.com/aburkov/theLMbook/blob/main/news_RNN_language_model.ipynb)
- [4.9. Transformer in Python](https://github.com/aburkov/theLMbook/blob/main/news_decoder_language_model.ipynb)
- [5.3.1. Baseline Emotion Classifier](https://github.com/aburkov/theLMbook/blob/main/emotion_classifier_LR.ipynb)
- [5.3.2. Emotion Generation](https://github.com/aburkov/theLMbook/blob/main/emotion_GPT2_as_text_generator.ipynb)
- [5.3.3. Finetuning to Follow Instructions](https://github.com/aburkov/theLMbook/blob/main/instruct_GPT2.ipynb)
- [5.4.4. Penalties](https://github.com/aburkov/theLMbook/blob/main/sampling_method.ipynb)
- [5.5.2. Parameter-Efficient Finetuning (PEFT)](https://github.com/aburkov/theLMbook/blob/main/emotion_GPT2_as_text_generator_LoRA.ipynb)
- [5.6. LLM as a Classifier](https://github.com/aburkov/theLMbook/blob/main/emotion_GPT2_as_classifier.ipynb)